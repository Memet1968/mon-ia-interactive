# üöÄ CLARA ORION 2032 - VERSION 3 IMMERSIVE
## Guide d'installation et de d√©ploiement

---

## üì¶ CE QUI A CHANG√â (v1 ‚Üí v3)

### ‚úÖ Am√©liorations majeures

1. **API LLM** (au lieu de Gemini)
   - Meilleur pour le roleplay immersif
   - Gratuit avec limites g√©n√©reuses
   - Plus coh√©rent dans la personnalit√©

2. **Persona Clara ultra-immersif**
   - 2031 (avant les √©v√©nements du roman)
   - R√©v√©lations progressives sur 7+ conversations
   - Protocole email pi√®ge (protocoleorion2032@proteux.org)
   - R√©f√©rences √† Biblioth√©caire pour le suspens

3. **Interface messagerie s√©curis√©e**
   - Style terminal Matrix/cyberpunk
   - Messages style WhatsApp/SMS
   - Indicateur "Clara √©crit..."
   - En-t√™te avec chiffrement quantique
   - Input fixe en bas (UX mobile native)

4. **Introduction naturelle**
   - Clara se pr√©sente elle-m√™me (pas d'intro automatique)
   - Premier message court et intrigant
   - Progression narrative fluide

---

## üìÅ STRUCTURE DU PROJET V3

```
clara-orion-2032-v3/
‚îú‚îÄ‚îÄ server.js                  # Backend LLM (NOUVEAU)
‚îú‚îÄ‚îÄ clara_prompt_v3.txt       # Persona immersif (NOUVEAU)
‚îú‚îÄ‚îÄ orion_lore_v3.txt         # Base connaissances (NOUVEAU)
‚îú‚îÄ‚îÄ package.json              # D√©pendances (mis √† jour)
‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îú‚îÄ‚îÄ index.html           # Interface messagerie (NOUVEAU)
‚îÇ   ‚îú‚îÄ‚îÄ styles.css           # Style terminal (NOUVEAU)
‚îÇ   ‚îî‚îÄ‚îÄ script.js            # Frontend UX (NOUVEAU)
‚îî‚îÄ‚îÄ README.md                 # Ce fichier
```

---

## üõ†Ô∏è INSTALLATION LOCALE

### √âtape 1 : Remplacer les fichiers

**Dans votre dossier `mon-ia-interactive` existant :**

1. **Remplacer `server.js`**
   ```bash
   # Sauvegarde de l'ancien (optionnel)
   mv server.js server_old.js
   
   # Copier le nouveau
   cp /chemin/vers/server_v3.js server.js
   ```

2. **Ajouter les nouveaux prompts**
   ```bash
   # Remplacer l'ancien prompt
   mv clara_prompt.txt clara_prompt_old.txt
   cp /chemin/vers/clara_prompt_v3.txt clara_prompt_v3.txt
   
   # Ajouter le fichier lore (nouveau)
   cp /chemin/vers/orion_lore_v3.txt orion_lore_v3.txt
   ```

3. **Remplacer le frontend**
   ```bash
   cd public/
   
   # Sauvegardes (optionnel)
   mv index.html index_old.html
   mv styles.css styles_old.css
   mv script.js script_old.js
   
   # Nouveaux fichiers
   cp /chemin/vers/index_v3.html index.html
   cp /chemin/vers/styles_v3.css styles.css
   cp /chemin/vers/script_v3.js script.js
   ```

4. **Mettre √† jour package.json**
   ```bash
   cd ..
   cp /chemin/vers/package_v3.json package.json
   ```

### √âtape 2 : Obtenir une cl√© API LLM

1. **Cr√©er un compte** : https://platform.llm.com
2. **Aller dans "API Keys"**
3. **Cr√©er une nouvelle cl√©** (copier et sauvegarder)

### √âtape 3 : Configurer la cl√© API

**Option A - Variable d'environnement (recommand√©) :**
```bash
# Mac/Linux
export LLM_API_KEY="sk-votre-cle-ici"

# Windows (PowerShell)
$env:LLM_API_KEY="sk-votre-cle-ici"
```

**Option B - Fichier .env (plus pratique) :**
```bash
# Cr√©er un fichier .env √† la racine
echo "LLM_API_KEY=sk-votre-cle-ici" > .env
```

Puis installer dotenv :
```bash
npm install dotenv
```

Et ajouter en haut de `server.js` :
```javascript
import dotenv from 'dotenv';
dotenv.config();
```

### √âtape 4 : Installer les d√©pendances

```bash
npm install
```

### √âtape 5 : Lancer en local

```bash
npm start
```

Ouvrir : http://localhost:3000

---

## ‚úÖ TEST EN LOCAL

### 1. V√©rifier le serveur

```bash
curl http://localhost:3000/health
```

R√©ponse attendue :
```json
{
  "ok": true,
  "model": "llm-chat",
  "hasApiKey": true
}
```

### 2. Tester l'interface

Ouvrir http://localhost:3000 dans votre navigateur.

**Vous devriez voir :**
- En-t√™te : "SECURE CHANNEL // MATRIX-2XTH-687"
- Message syst√®me avec ic√¥ne üîí
- Premier message de Clara
- Input de saisie en bas

### 3. Tester la conversation

**Message 1 (vous) :**
```
Bonjour
```

**R√©ponse attendue (Clara) :**
```
Vous √™tes l√†. Bien.
Ce canal ne garde aucune trace.

On m'appelle Clara.
Je ne dirai pas d'o√π je parle.

Vous avez √©t√© rep√©r√©. Pas par nous.
Par ORION.

Vous connaissez ce nom ?
```

**Message 2 (vous) :**
```
Non
```

**R√©ponse attendue (Clara) :**
```
Un syst√®me de classification cognitive.
480 milliards de dollars par an.
Glass-Eyes, Hung, Benif.

Le but ?
D√©cider qui est apte √† gouverner.
Et qui est "chestless".
Sans poitrine.

Vous comprenez ce que √ßa signifie ?
```

### 4. V√©rifier la tonalit√©

**Clara doit √™tre :**
- ‚úÖ Directe (phrases courtes)
- ‚úÖ M√©fiante (teste l'utilisateur)
- ‚úÖ Clinique (pas de pathos excessif)
- ‚úÖ R√©volt√©e (sous-jacent)
- ‚úÖ En 2031 (ne parle PAS d'Adam ou de 2032)

**Clara NE DOIT PAS :**
- ‚ùå Dire "je suis un chatbot"
- ‚ùå Donner trop d'infos d'un coup
- ‚ùå R√©v√©ler son nom complet
- ‚ùå Parler des √©v√©nements de 2032

---

## üåê D√âPLOIEMENT SUR RENDER

### √âtape 1 : Pousser sur GitHub

```bash
# Initialiser Git (si pas d√©j√† fait)
git init

# Ajouter tous les fichiers
git add .

# Commit
git commit -m "Version 3 - Interface immersive + LLM"

# Ajouter le remote (remplacer par votre repo)
git remote add origin https://github.com/votre-username/clara-orion-2032.git

# Pousser
git push -u origin main
```

### √âtape 2 : Cr√©er le service sur Render

1. **Aller sur** https://render.com
2. **Cliquer sur "New" ‚Üí "Web Service"**
3. **Connecter votre repo GitHub**
4. **Configuration :**
   - **Name:** `clara-orion-2032`
   - **Environment:** `Node`
   - **Build Command:** `npm install`
   - **Start Command:** `npm start`
   - **Plan:** Free (pour commencer)

### √âtape 3 : Ajouter la variable d'environnement

Dans les settings du service Render :

1. **Aller dans "Environment"**
2. **Ajouter une variable :**
   - **Key:** `LLM_API_KEY`
   - **Value:** `sk-votre-cle-llm`
3. **Sauvegarder**

### √âtape 4 : D√©ployer

Render va automatiquement :
- ‚úÖ Cloner votre repo
- ‚úÖ Installer les d√©pendances
- ‚úÖ Lancer le serveur

**URL g√©n√©r√©e :** https://clara-orion-2032.onrender.com

---

## üé® PERSONNALISATION (OPTIONNEL)

### Changer le nom du canal

Dans `index.html`, ligne 14 :
```html
<span class="header-title">SECURE CHANNEL // MATRIX-2XTH-687</span>
```

Remplacer par :
```html
<span class="header-title">VOTRE-NOM-ICI</span>
```

### Changer les couleurs

Dans `styles.css`, lignes 6-14 :
```css
:root {
    --bg-dark: #0a0e14;           /* Fond principal */
    --text-accent: #00ff88;       /* Vert Matrix */
    --text-warning: #ff9500;      /* Orange utilisateur */
    /* ... */
}
```

### Modifier le premier message de Clara

Dans `index.html`, lignes 42-50 (message automatique de Clara) :

Ou encore mieux : **supprimer ce message** et laisser Clara se pr√©senter via l'API uniquement.

---

## üêõ D√âPANNAGE

### Erreur : "Missing LLM_API_KEY"

**Cause :** La cl√© API n'est pas configur√©e

**Solution :**
```bash
# V√©rifier que la variable existe
echo $LLM_API_KEY  # Mac/Linux
echo $env:LLM_API_KEY  # Windows

# Si vide, la red√©finir
export LLM_API_KEY="sk-..."
```

### Erreur : "LLM HTTP 401"

**Cause :** Cl√© API invalide ou expir√©e

**Solution :**
1. V√©rifier la cl√© sur https://platform.llm.com
2. R√©g√©n√©rer une nouvelle cl√©
3. Mettre √† jour la variable d'environnement

### Clara r√©pond bizarrement

**Cause possible :** Les fichiers de prompt ne sont pas charg√©s correctement

**Solution :**
```bash
# V√©rifier que les fichiers existent
ls -la clara_prompt_v3.txt
ls -la orion_lore_v3.txt

# V√©rifier les droits de lecture
chmod +r clara_prompt_v3.txt
chmod +r orion_lore_v3.txt

# Relancer le serveur
npm start
```

### L'interface ne s'affiche pas correctement

**Cause :** Fichiers CSS/JS non charg√©s

**Solution :**
```bash
# V√©rifier la structure
ls -la public/
# Doit contenir : index.html, styles.css, script.js

# V√©rifier que Express sert le dossier public
# Dans server.js, ligne 19 :
app.use(express.static("public"));
```

### Le scroll automatique ne fonctionne pas

**Cause :** Probl√®me CSS avec le conteneur

**Solution :**
Dans `styles.css`, v√©rifier lignes 85-88 :
```css
.chat-container {
    flex: 1;
    overflow-y: auto;  /* Important */
    padding-bottom: 160px;  /* Espace pour l'input */
}
```

---

## üìä COMPARAISON DES VERSIONS

| Fonctionnalit√© | v1 (Gemini) | v3 (LLM) |
|----------------|-------------|---------------|
| API | Gemini | LLM |
| Co√ªt | Gratuit | Gratuit |
| Persona | Biblioth√©caire technique | Clara immersive |
| Univers | Absent | Complet (H0/H1/H2, MODUS, etc.) |
| Interface | Standard | Terminal s√©curis√© |
| UX | Form classique | Messagerie mobile |
| Intro | Automatique (longue) | Naturelle (progressive) |
| Suspens | Non | Oui (Biblioth√©caire, etc.) |
| Email pi√®ge | Non | Oui (protocoleorion2032@proteux.org) |

---

## üìû SUPPORT

**Auteur :** Ahmed Messaoudi  
**Roman :** ORION 2032

**En cas de probl√®me :**
1. V√©rifier les logs du serveur (`npm start`)
2. Tester `/health` endpoint
3. V√©rifier la cl√© API LLM
4. Comparer avec les exemples de ce guide

---

## üéâ C'EST PR√äT !

Vous avez maintenant une **interface immersive ultra-professionnelle** pour votre chatbot Clara.

**Prochaines √©tapes :**
1. ‚úÖ Tester en local
2. ‚úÖ D√©ployer sur Render
3. ‚úÖ Partager avec vos lecteurs
4. ‚úÖ Collecter les retours
5. ‚úÖ It√©rer et am√©liorer

**Bon lancement ! üöÄ**
